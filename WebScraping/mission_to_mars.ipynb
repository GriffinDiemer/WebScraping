{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scrape everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary will hold everything we pull from all the sites\n",
    "scraped_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\" # probably need to replace this since it redirects\n",
    "#site1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(news_url)\n",
    "# use beautiful soup to parse the url above\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bs to find() the example_title_div and filter on the class_='content_tile'\n",
    "results = soup.find_all('div', class_=\"content_title\")\n",
    "body_results = soup.find_all('div', class_=\"article_teaser_body\")\n",
    "#within_elements = divs.first.find_by_class(\"content_title\")\n",
    "#news_title = \"FILL IN THE TITLE\"\n",
    "#scraped_data['news_title'] = news_title\n",
    "\n",
    "# use bs to find() the example_title_div and filter on the class_='article_teaser_body'\n",
    "\n",
    "#news_p = \"FILL IN THE PARAGRAPH\"\n",
    "#scraped_data['news_p'] = news_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Curiosity Rover Finds an Ancient Oasis on Mars\n",
      "New evidence suggests salty, shallow ponds once dotted a Martian crater — a sign of the planet's drying climate.\n"
     ]
    }
   ],
   "source": [
    "title = results[0].find('a').text\n",
    "body = body_results[0].text\n",
    "print(title)\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "#site2\n",
    "url = \"https://www.jpl.nasa.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(picture_url)\n",
    "# use beautiful soup to parse the url above\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA18811_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "#browser.find_by_id('full_image').first.click()\n",
    "results = soup.find_all('article', class_='carousel_item')\n",
    "picture = results[0].a['data-fancybox-href']\n",
    "featured_image_url = url+picture\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 3 - https://twitter.com/marswxreport?lang=en\n",
    "twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(twitter_url)\n",
    "# use beautiful soup to parse the url above\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "# grab the latest tweet and be careful its a weather tweet\n",
    "\n",
    "# Example:\n",
    "#mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_pic = results[0].find('a').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pic.twitter.com/sSOjseIl81'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = results[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 309 (2019-10-10) low -102.3ºC (-152.1ºF) high -26.2ºC (-15.1ºF)\\nwinds from the SSE at 6.1 m/s (13.6 mph) gusting to 18.9 m/s (42.4 mph)\\npressure at 7.20 hPapic.twitter.com/sSOjseIl81'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather= mars_weather.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather= mars_weather.replace(twitter_pic, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 309 (2019-10-10) low -102.3ºC (-152.1ºF) high -26.2ºC (-15.1ºF)winds from the SSE at 6.1 m/s (13.6 mph) gusting to 18.9 m/s (42.4 mph)pressure at 7.20 hPa'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 4 - \n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(facts_url)\n",
    "# use beautiful soup to parse the url above\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "facts_df = pd.read_html(facts_url)[0]\n",
    "browser.quit()\n",
    "# convert facts_df to a html string and add to dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df.to_html('facts_html.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(mars_url)\n",
    "# use beautiful soup to parse the url above\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 5\n",
    "names = []\n",
    "hemisphere_image = []\n",
    "base_url = 'https://astrogeology.usgs.gov'\n",
    "results = soup.find_all('h3')\n",
    "for result in results:\n",
    "    planet_name = result.text\n",
    "    names.append(planet_name)\n",
    "\n",
    "#This only worked with me telling soup that this is a new page. I am sure it isn't supposed to work this way. \n",
    "#Was the loop what was messing it up? \n",
    "    \n",
    "for name in names:\n",
    "    browser.visit(mars_url)\n",
    "    time.sleep(1)\n",
    "    browser.click_link_by_partial_text(name)\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    time.sleep(1)\n",
    "    pic = soup.find('img', class_='wide-image')\n",
    "    hemisphere_image.append(pic)\n",
    "# use bs4 to scrape the title and url and add to dictionary\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img class=\"wide-image\" src=\"/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg\"/>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "for picture in hemisphere_image:\n",
    "    link = picture['src']\n",
    "    full_link = base_url + link\n",
    "    hemisphere_image_urls.append(full_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_stuff = []\n",
    "for x in range(4):\n",
    "    space_stuff.append({\"title\":names[x],\"img_url\": hemisphere_image_urls[x]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], []]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File-> download as python into a new module called scrape_mars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use day 3 09-Ins_Scrape_And_Render/app.py as a blue print on how to finish the homework.\n",
    "\n",
    "# replace the contents of def index() and def scraper() appropriately.\n",
    "\n",
    "# change the index.html to render the site with all the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
